# Key concepts of Parsing Theory

Key concepts of Parsing Theory.

<!-- [:arrow_down: Tags legend](#tags-legend) at the end of the page. -->

<!-- - []() by []() ( _:movie_camera:_ ) -->

<!-- ## Architecture -->

## Chomsky's hierarchy of grammars

##### Type 0: **Unrestricted Grammar**
- Production Rule: α → β
  - α is a string of terminals and/or non-terminals with at least one non-terminal
  - β is a string of terminals and/or non-terminals
- Can generate any language that can be recognized by a Turing machine.

##### Type 1: **Context-Sensitive Grammar** ~ **CSG**
- Production Rule: αAβ → αγβ
  - A is a non-terminal
  - α, β, γ are strings of terminals and/or non-terminals
- The length of αβ must be less than or equal to the length of αγβ.
- Can generate context-sensitive languages.

##### Type 2: **Context-Free Grammar** ~ **CFG**
- Production Rule: A → γ
  - A is a non-terminal
  - γ is a string of terminals and/or non-terminals
- Can generate context-free languages, which are recognized by pushdown automata.

##### Type 3: **Regular Grammar**
- Right Linear Grammar (RLG):
  - Production Rule: A → aB or A → a
    - A and B are non-terminals
    - a is a terminal
- Left Linear Grammar (LLG):
  - Production Rule: A → Ba or A → a
    - A and B are non-terminals
    - a is a terminal
- Can generate regular languages, which are recognized by finite automata.

## RLG ~ Right Linear Grammar

A type of regular grammar where production rules are of the form A → aB or A → a, with non-terminals appearing on the right side of the terminal. Where A and B are non-terminals and a is a terminal.

## LLG ~ Left Linear Grammar

A type of regular grammar where production rules are of the form A → Ba or A → a, with non-terminals appearing on the left side of the terminal. Where A and B are non-terminals and a is a terminal.

## Left Most Derivative ~ Leftmost Derivation

A process in formal grammar where the leftmost non-terminal in a string is replaced first during each step of the derivation sequence. This concept is particularly relevant to context-free grammars (CFGs) and is commonly used in parsing techniques like LL parsers, which read input from left to right and construct a leftmost derivation of the sentence.

## Right Most Derivative ~ Rightmost Derivation

A process in formal grammar where the rightmost non-terminal in a string is replaced first during each step of the derivation sequence. This is especially relevant to context-free grammars (CFGs) and is used in parsing techniques like LR parsers, which read input from left to right and construct a rightmost derivation in reverse.

## Context-Free Grammar / Regular Grammar

**Regular Grammar**

- **Definition**: Regular grammars have rules where a non-terminal is replaced by a terminal, optionally followed by another non-terminal.
- **Expressive Power**: Less powerful than CFGs; cannot handle nested structures.
- **Parsing**: Uses simple and efficient algorithms like finite state machines or regular expression engines.
- **Applications**: Used in lexical analysis to define the structure of tokens in programming languages and in text processing tools like grep and sed.

**Context-Free Grammar (CFG)**

- **Definition**: CFGs have production rules where a single non-terminal is replaced by a string of terminals and/or non-terminals.
- **Expressive Power**: More powerful than regular grammars; can describe languages with nested structures, such as balanced parentheses.
- **Parsing**: Requires more complex parsing techniques, such as LL, LR, or CYK parsers, to handle recursive and nested structures.
- **Applications**: Widely used in the design of programming languages and compilers, where the syntax of the language is often context-free.

**Example of CFG**: Balanced Parentheses
  - Grammar:
    - S → empty string
    - S → (S)
    - S → SS

This CFG can generate all strings of balanced parentheses, a task that regular grammars cannot accomplish due to their inability to handle nested or recursive patterns.

## Ambiguity in CFG

Ambiguity in grammar occurs when a single string can be generated by a grammar in more than one distinct way, resulting in multiple parse trees or derivations. This means that the grammar allows for more than one interpretation of the structure of the string.

Ambiguity is particularly relevant to context-free grammars (CFGs) because they are often used to define the syntax of programming languages, where unambiguous interpretation is crucial. However, ambiguity can also occur in other types of grammars, but it is most commonly discussed in the context of CFGs due to their widespread use in language parsing and compiler design.

```text

Context Free Grammar: E → E + E | E × E | id

Left Most Derivation:     Right Most Derivation:    Parse Tree Derivation:

 E ⇒ E + E                 E ⇒ E + E                    E
   ⇒ id + E                  ⇒ E + E × E               / \
   ⇒ id + E x E              ⇒ E + E × id             E + E
   ⇒ id + id x E             ⇒ E + id × id            |   /\
   ⇒ id + id x id            ⇒ id + id × id          id  E * E
                                                          |   |
                                                         id   id

 E ⇒ E x E                 E ⇒ E x E                     E
   ⇒ E + E x E               ⇒ E x id                   / \
   ⇒ id + E x E              ⇒ E + E x id              E * E
   ⇒ id + id x E             ⇒ E + id x id            / \  |
   ⇒ id + id x id            ⇒ id + id x id          E + E id
                                                      |   |
                                                     id  id
```

## Parsing Expression Grammar ~ PEG

A formal grammar framework used to describe the syntax of languages, offering an alternative to Context-Free Grammars (CFGs) with unique features.

## PEG / CFG

PEGs offer a powerful alternative to CFGs for defining and implementing parsers, especially when deterministic parsing is required.

PEGs differ from CFGs in that they use a deterministic choice operator, which eliminates ambiguity by always selecting the first successful match in a sequence of alternatives. This makes PEGs particularly useful for programming language parsers, as they can handle complex syntax rules without ambiguity. PEGs are often implemented using **packrat parsers**, which provide linear-time parsing by caching intermediate results.

PEGs are well-suited for tasks where precise control over parsing decisions is required, and they allow for more straightforward implementation of certain language features compared to CFGs.

- **Determinism**: PEGs use ordered choice, ensuring deterministic parsing by selecting the first successful match, which can lead to the prefix capture problem where earlier alternatives capture input, requiring careful rule ordering. CFGs allow ambiguity with multiple parse trees for the same input string.
- **Parsing Strategy**: PEGs typically use packrat parsers for linear-time parsing by caching results, whereas CFGs use strategies like LL, LR, or CYK, which may involve backtracking or complex table-driven methods.
- **Expressive Power**: PEGs can express all deterministic context-free languages and some languages CFGs cannot due to ambiguity, while CFGs can express a broader range of context-free languages, including ambiguous ones.
- **Grammar**: PEGs include constructs like sequence, ordered choice, repetition, and lookahead predicates, whereas CFGs use production rules that map non-terminals to strings of terminals and non-terminals.
- **Complexity**: PEGs achieve linear-time complexity for deterministic parsing with packrat parsing, while CFGs' best parsing algorithms, like CYK, have a time complexity of cubic time, though deterministic parts of CFGs can run in linear time.
- **Semantics**: PEGs have intensional semantics, where the language is defined by the sentences recognized, similar to top-down recursive-descent parsers. CFGs have extensional semantics, where the language is the set of sentences obtained by derivation.

###### Origin

The term "Parsing Expression Grammar" was introduced by Bryan Ford in his 2004 paper, proposing PEGs as an alternative to CFGs for deterministic and unambiguous syntax specification.

###### Example

A simple PEG for arithmetic expressions:

```
Expression <- Term (('+' / '-') Term)*
Term       <- Factor (('*' / '/') Factor)*
Factor     <- Number / '(' Expression ')'
Number     <- [0-9]+
```

## PEG - Key Characteristics

1. **Deterministic Parsing**: PEGs are designed to be deterministic, eliminating ambiguity through ordered choice, where the first matching alternative is selected.

2. **Syntax**: Uses constructs like sequence, ordered choice, repetition, and lookahead predicates (not and and) to define grammar rules.

3. **Expressive Power**: Can express all deterministic context-free languages and some languages CFGs cannot due to ambiguity, but not all context-sensitive languages.

4. **Applications**: Used in parsing programming languages, data formats, and structured text, particularly where deterministic parsing is desired.

5. **Advantages**: Provides a clear, concise way to define grammars without ambiguity, allowing for straightforward parsing algorithms without backtracking.

## Left Recursion / Right Recursion

```text

Left Recursion ~ Left Associativity

A → Aα | β

  A                  A                   A
  |                 / \                 / \
  β                A   α               A   α
                   |                  / \
                   β                 A   α
                                     |
                                     β

Right Recursion ~ Right Associativity

A → αA | β

  A                  A                  A
  |                 / \                / \
  β                α   A              α   A
                       |                 / \
                       β                α   A
                                            |
                                            β

```

## Elimination of Left Recursion

If left recursion is indirect (involving multiple non-terminals), the grammar must first be transformed to remove indirect recursion by reordering or rewriting rules.

Direct left recursion occurs when a non-terminal directly calls itself on the left side of its production. By eliminating left recursion, the grammar becomes suitable for top-down parsing methods, which require non-left-recursive ( in case of parsing from left to right ) grammars to function correctly.

```text

Original Grammar Rule:
  A → Aα | β

Transformed Grammar to Remove Left Recursion:
  A → βA'
  A' → αA' | ε
```

## Left Refactoring

Left factoring is a technique used to transform a grammar to convert it into deteministic one to make it suitable for predictive parsing, such as LL parsers.

It is applied when a grammar has production rules with common prefixes, which can cause ambiguity in deciding which production to use during parsing. Left factoring helps eliminate this ambiguity by restructuring the grammar. But bear in mind that deterministic grammar does not guarantee unambiguous.

Left Factoring Process

```text
  Identify Common Prefixes:
    Look for non-terminals with multiple productions that share a common prefix. For example, consider the productions:
      A → αβ₁
      A → αβ₂

  Factor Out the Common Prefix:
    Introduce a new non-terminal to represent the common prefix and rewrite the productions. For the example above:
      Introduce a new non-terminal A'.
      Rewrite the productions as:
        A → αA'
        A' → β₁ | β₂

  Example

    Original Grammar:
      A → aAB | aBc | aAc

    Intermidiary Step:
      A → aA'
      A' → AB | Ac | Bc

    Refactored Grammar:
      A → aA'
      A' → AA'' | Bc
      A'' → B | c

  Ambigious Example

    Original Grammar:
      S → iEtS | iEtSeS | a
      E → b

    Refactored Grammar:
      S → iEtSS' | a
      S' → ε | eS
      E → b

  Example

    Original Grammar:
      S → aSSbS | aSaSb | abb | b

    Intermidiary Step:
      S → aS' | b
      S' → SSbS | SaSb | bb

    Refactored Grammar:
      S → aS' | b
      S' → SS'' | bb
      S'' → SbS | aSb

  Example

    Original Grammar:
      S → bSSaaS | bSSaSb | bSb | a

    Intermidiary Step:
      S → bS' | a
      S' → SaaS | SaSb | b

    Refactored Grammar:
      S → bSS' | a
      S' → SaS'' | b
      S'' → aS | Sb

  Example

    Original Grammar:
      S → a | ab | abc | abcd

    Refactored Grammar:
      S → aS'
      S' → bS'' | ε
      S'' → cS''' | ε
      S''' → d | ε

```

## First, Follow Functions

The First function helps determine which terminal symbols can appear at the beginning of strings derived from a given grammar symbol.

The Follow function determines which terminal symbols can appear immediately after a non-terminal in some "sentential" form.

> Example

| Production | FIRST     | FOLLOW   |
|------------|-----------|----------|
| S → ABCDE  | {a, b, c} | {$}      |
| A → a      | {a, ε}    | {b, c}   |
| B → b      | {b, ε}    | {c}      |
| C → c      | {c}       | {d, e, $}|
| D → d      | {d, ε}    | {e, $}   |
| E → e      | {e, ε}    | {$}      |

> Example

| Production | FIRST    | FOLLOW   |
|------------|----------|----------|
| S → aBDh   | {a}      | {$}      |
| B → c      | {c}      | {g, f, h}|
| C → bC ε   | {b, ε}   | {g, f, h}|
| D → EF     | {g, f, ε}| {g, f, h}|
| E → g ε    | {g, ε}   | {f, h}   |
| F → f ε    | {f, ε}   | {h}      |
